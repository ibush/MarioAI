source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
}
# Analysis of runtime
rt_data <- data.frame()
nvars <- list(small=4, medium=10, large=50)
for(dataset_size in dataset_sizes){
for(m in methods){
filename <- paste0(meta_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
rdata <- read.csv(filename)
rdata <- subset(rdata, select=c('runtime'))
rdata$method <- m
rdata$size <- dataset_size
rdata$nvars <- nvars[[dataset_size]]
rt_data <- rbind(rt_data, rdata)
}
}
g <- ggplot(rt_data, aes(x=nvars, y=log(runtime), colour=method)) + geom_line() +
ggtitle('Method Log Runtimes') + labs(x='Number of Variables', y='Runtime (Log seconds)',colour='Search Method')
pdf(paste0(wd,"writeup/imgs/method_runtimes.pdf"), width=12,height=6)
plot(common_format(g))
dev.off()
library(igraph)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
data_dir <- paste0(wd, 'data/')
struct_dir <- paste0(wd, 'struct/')
img_dir <- paste0(wd,"writeup/imgs/")
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
small_name <- 'k2search_small'
medium_name <- 'localsearch_medium'
large_name <- 'k2search_large'
# Load datasets
dataset_small <- read.csv(paste0(data_dir, 'small.csv'))
dataset_medium <- read.csv(paste0(data_dir, 'medium.csv'))
dataset_large <- read.csv(paste0(data_dir, 'large.csv'))
# Generate graph for small network
small_mat <- as.matrix(read.csv(paste0(struct_dir, small_name, ".csv"), header=FALSE))
colnames(small_mat) <- names(dataset_small)
g <- graph.adjacency(small_mat)
pdf(paste0(img_dir,small_name,'_net.pdf'))
plot(g)
dev.off()
# Generate graph for medium network
medium_mat <- as.matrix(read.csv(paste0(struct_dir, medium_name, ".csv"), header=FALSE))
colnames(medium_mat) <- names(dataset_medium)
g <- graph.adjacency(medium_mat)
pdf(paste0(img_dir,medium_name,'_net.pdf'))
plot(g)
dev.off()
# Generate graph for large network
large_mat <- as.matrix(read.csv(paste0(struct_dir, large_name, ".csv"), header=FALSE))
g <- graph.adjacency(large_mat)
V(g)$name <- ""
#V(g)$size <- 1
pdf(paste0(img_dir,large_name,'_net.pdf'))
plot(g)
dev.off()
#pdf(paste0(network_graphs_dir,'/', date_string,'.pdf'))
#plot(g, main=paste0(date_string,' |V|=',vcount(g), ' |E|=', ecount(g)))
#dev.off()
library(igraph)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
data_dir <- paste0(wd, 'data/')
struct_dir <- paste0(wd, 'struct/')
img_dir <- paste0(wd,"writeup/imgs/")
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
small_name <- 'k2search_small'
medium_name <- 'localsearch_medium'
large_name <- 'k2search_large'
# Load datasets
dataset_small <- read.csv(paste0(data_dir, 'small.csv'))
dataset_medium <- read.csv(paste0(data_dir, 'medium.csv'))
dataset_large <- read.csv(paste0(data_dir, 'large.csv'))
# Generate graph for small network
small_mat <- as.matrix(read.csv(paste0(struct_dir, small_name, ".csv"), header=FALSE))
colnames(small_mat) <- names(dataset_small)
g <- graph.adjacency(small_mat)
pdf(paste0(img_dir,small_name,'_net.pdf'))
plot(g)
dev.off()
# Generate graph for medium network
medium_mat <- as.matrix(read.csv(paste0(struct_dir, medium_name, ".csv"), header=FALSE))
colnames(medium_mat) <- names(dataset_medium)
g <- graph.adjacency(medium_mat)
pdf(paste0(img_dir,medium_name,'_net.pdf'))
plot(g)
dev.off()
# Generate graph for large network
large_mat <- as.matrix(read.csv(paste0(struct_dir, large_name, ".csv"), header=FALSE))
g <- graph.adjacency(large_mat)
V(g)$name <- ""
#V(g)$size <- 1
pdf(paste0(img_dir,large_name,'_net.pdf'))
plot(g)
dev.off()
#pdf(paste0(network_graphs_dir,'/', date_string,'.pdf'))
#plot(g, main=paste0(date_string,' |V|=',vcount(g), ' |E|=', ecount(g)))
#dev.off()
rm(list=ls())
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
}
# Analysis of runtime
rt_data <- data.frame()
nvars <- list(small=4, medium=10, large=50)
for(dataset_size in dataset_sizes){
for(m in methods){
filename <- paste0(meta_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
rdata <- read.csv(filename)
rdata <- subset(rdata, select=c('runtime'))
rdata$method <- m
rdata$size <- dataset_size
rdata$nvars <- nvars[[dataset_size]]
rt_data <- rbind(rt_data, rdata)
}
}
g <- ggplot(rt_data, aes(x=nvars, y=log(runtime), colour=method)) + geom_line() +
ggtitle('Method Log Runtimes') + labs(x='Number of Variables', y='Runtime (Log seconds)',colour='Search Method')
pdf(paste0(wd,"writeup/imgs/method_runtimes.pdf"), width=12,height=6)
plot(common_format(g))
dev.off()
rm(list=ls())
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
all_data <- data.frame()
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
# Generate chart of log bayesian scores
all_data <- rbind(all_data, best_scores)
}
View(all_data)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
all_data <- data.frame()
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
# Generate chart of log bayesian scores
best_scores$dataset <- dataset_size
all_data <- rbind(all_data, best_scores)
}
View(best_scores)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
scoretable_data <- data.frame()
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
# Generate chart of log bayesian scores
best_scores$dataset <- dataset_size
scoretable_data <- rbind(scoretable_data, best_scores)
}
View(scoretable_data)
library(reshape2)
View(scoretable_data)
View(scoretable_data)
View(scoretable_data)
scoretable_data <- subset(scoretable_data, select=c('method','dataset','score'))
dcast(scoretable_data, method ~ dataset)
dcast(scoretable_data, dataset ~ method)
cat(print(xtable(blockchain)), file=paste0(wd, "writeup/score_table.tex"))
library(xtable)
cat(print(xtable(blockchain)), file=paste0(wd, "writeup/score_table.tex"))
table <- dcast(scoretable_data, dataset ~ method)
cat(print(xtable(table)), file=paste0(wd, "writeup/score_table.tex"))
# Analysis of runtime
rt_data <- data.frame()
nvars <- list(small=4, medium=10, large=50)
for(dataset_size in dataset_sizes){
for(m in methods){
filename <- paste0(meta_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
rdata <- read.csv(filename)
rdata <- subset(rdata, select=c('runtime'))
rdata$method <- m
rdata$size <- dataset_size
rdata$nvars <- nvars[[dataset_size]]
rt_data <- rbind(rt_data, rdata)
}
}
View(rt_data)
rt_data$dataset <- rt_data$size
table <- subset(rt_data, select=c('method','dataset','runtime'))
table <- dcast(table, dataset ~ method)
cat(print(xtable(table)), file=paste0(wd, "writeup/rt_table.tex"))
View(table)
rm(list=ls())
library(ggplot2)
library(dplyr)
library(scales)
library(grid)
library(reshape2)
library(xtable)
#scatter plot of random small
wd <- '~/Desktop/fall15/cs238/project1/'
hist_dir <- paste0(wd, 'hist/')
meta_dir <- paste0(wd, 'meta/')
source(paste0(wd,"src/graph_utils.R"))
dataset_sizes <- c('small','medium','large')
methods <- c('randomcheck','k2search','localsearch','rlocalsearch','localsearch_est_lr', 'k2search_est_lr')
scoretable_data <- data.frame()
for(dataset_size in dataset_sizes){
all_data <- data.frame()
for(m in methods){
filename <- paste0(hist_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
mdata <- read.csv(filename)
mdata <- subset(mdata, select=c('score'))
mdata$method <- m
mdata$iters <- 1:nrow(mdata)
all_data <- rbind(all_data, mdata)
}
# Bar chart of best score from all methods
best_scores <- summarise(group_by(all_data,method),iters=n(), score=max(score))
max_score <- max(best_scores$score)
min_score <- min(best_scores$score)
srange <- max_score - min_score
lower_limit <- min_score - max(0.2 * srange,10)
upper_limit <- max_score + max(0.2 * srange,10)
g <- ggplot(best_scores, aes(x=method,y=score,fill=factor(method))) + geom_bar(stat="identity") +
coord_cartesian(ylim=c(lower_limit,upper_limit)) +
scale_y_continuous(labels=comma) +
labs(x="Search Method",y="Log Bayesian Score") + ggtitle(paste0("Results - Dataset ",dataset_size)) +
theme(legend.position="none", axis.text.x = element_text(angle = 45, hjust = 1))
pdf(paste0(wd,"writeup/imgs/bestscores_",dataset_size,".pdf"))
plot(common_format(g))
dev.off()
# Generate chart of log bayesian scores
best_scores$dataset <- dataset_size
scoretable_data <- rbind(scoretable_data, best_scores)
}
# Output best scores table
scoretable_data <- subset(scoretable_data, select=c('method','dataset','score'))
table <- dcast(scoretable_data, method ~ dataset)
cat(print(xtable(table)), file=paste0(wd, "writeup/score_table.tex"))
# Analysis of runtime
rt_data <- data.frame()
nvars <- list(small=4, medium=10, large=50)
for(dataset_size in dataset_sizes){
for(m in methods){
filename <- paste0(meta_dir, m, '_',dataset_size, '.csv')
if (!file.exists(filename)){next}
rdata <- read.csv(filename)
rdata <- subset(rdata, select=c('runtime'))
rdata$method <- m
rdata$size <- dataset_size
rdata$nvars <- nvars[[dataset_size]]
rt_data <- rbind(rt_data, rdata)
}
}
g <- ggplot(rt_data, aes(x=nvars, y=log(runtime), colour=method)) + geom_line() +
ggtitle('Method Log Runtimes') + labs(x='Number of Variables', y='Runtime (Log seconds)',colour='Search Method')
pdf(paste0(wd,"writeup/imgs/method_runtimes.pdf"), width=12,height=6)
plot(common_format(g))
dev.off()
rt_data$dataset <- rt_data$size
table <- subset(rt_data, select=c('method','dataset','runtime'))
table <- dcast(table, method~dataset)
cat(print(xtable(table)), file=paste0(wd, "writeup/rt_table.tex"))
?read.csv
setwd('~/Desktop/MarioAI/proj')
wd <- ''
outdir <- paste0(wd, 'writeup/')
datadir <- paste0(wd, 'data')
data <- read.table(paste0(datadir, 'distance1'))
datadir <- paste0(wd, 'data/')
data <- read.table(paste0(datadir, 'distance1'))
View(data)
all_data <- data.frame()
hbind(all_data,data)
cbind(all_data,data)
1:5
rm(list=ls())
wd <- ''
outdir <- paste0(wd, 'writeup/')
datadir <- paste0(wd, 'data/')
for(i in 1:40){
dist_file <- paste0(datadir, 'distance',i)
fit_file <- paste0(datadir, 'fitnessScores',i)
if(i == 1){
distance <- read.table(dist_file)
fitness <- read.table(fit_file)
}else{
distance <- cbind(distance, read.table(dist_file))
fitness <- cbind(fitness, read.table(fit_file))
}
}
View(distance)
names(distance)
distance$V1
View(distance)
sum(dist)
sum(distance)
colSum(distance)
colSums(distance)
colSums(distance)/100
rowSums(distance)/100
rowSums(distance)/40
rowSums(distance)
rm(list=ls())
# Output baseline by combining distance and fitness scores across 40 levels and averaging across trials
library(xtable)
wd <- ''
outdir <- paste0(wd, 'writeup/')
datadir <- paste0(wd, 'data/')
for(i in 1:40){
dist_file <- paste0(datadir, 'distance',i)
fit_file <- paste0(datadir, 'fitnessScores',i)
if(i == 1){
distance <- read.table(dist_file)
fitness <- read.table(fit_file)
}else{
distance <- cbind(distance, read.table(dist_file))
fitness <- cbind(fitness, read.table(fit_file))
}
}
dist_sum <- rowSums(distance)
fit_sum <- rowSums(fitness)
print(paste("Average Distance Sum:",dist_sum))
print(paste("Average Fitness Sum:",fit_sum))
rm(list=ls())
# Output baseline by combining distance and fitness scores across 40 levels and averaging across trials
library(xtable)
wd <- ''
outdir <- paste0(wd, 'writeup/')
datadir <- paste0(wd, 'data/')
for(i in 1:40){
dist_file <- paste0(datadir, 'distance',i)
fit_file <- paste0(datadir, 'fitnessScores',i)
if(i == 1){
distance <- read.table(dist_file)
fitness <- read.table(fit_file)
}else{
distance <- cbind(distance, read.table(dist_file))
fitness <- cbind(fitness, read.table(fit_file))
}
}
dist_sum <- rowSums(distance)
fit_sum <- rowSums(fitness)
print(paste("Average Distance Sum:",mean(dist_sum)))
print(paste("Average Fitness Sum:",mean(fit_sum)))
